# Домашнее задание к занятию "6.6. Troubleshooting"

## Задача 1

Перед выполнением задания ознакомьтесь с документацией по [администрированию MongoDB](https://docs.mongodb.com/manual/administration/).

Пользователь (разработчик) написал в канал поддержки, что у него уже 3 минуты происходит CRUD операция в MongoDB и её 
нужно прервать. 

Вы как инженер поддержки решили произвести данную операцию:
- напишите список операций, которые вы будете производить для остановки запроса пользователя   
*Для поиска исполняющейся операции используем: db.currentOp({"secs_running":{$gte: 180}}) 
Завершаем операцию по op id: db.killOp(opid)*   

- предложите вариант решения проблемы с долгими (зависающими) запросами в MongoDB

*Необходимо воспользоваться механизмами профилирования и explain, чтобы понять причины медленных запросов. Наверно/обычно она кроется в большом кол-ве данных для выборки. Это обычно вызывает всплекс CPU. Так что варианты: дадим больше CPU, пофиксим текущие индексы в таблице (добавим новые), партиционируем. Еще можно воспользоваться параметром maxTimeMS(), где мы просто будем прерывать команду по таймингу, но мы таким образом не убираем причину.*

## Задача 2

Перед выполнением задания познакомьтесь с документацией по [Redis latency troobleshooting](https://redis.io/topics/latency).

Вы запустили инстанс Redis для использования совместно с сервисом, который использует механизм TTL. 
Причем отношение количества записанных key-value значений к количеству истёкших значений есть величина постоянная и
увеличивается пропорционально количеству реплик сервиса. 

При масштабировании сервиса до N реплик вы увидели, что:
- сначала рост отношения записанных значений к истекшим
- Redis блокирует операции записи

Как вы думаете, в чем может быть проблема?

*Рост числа устаревший записей приводит к блокировке Редисом операции записи, потому что Redis не успевает их чистить.
Каждые 100мс redis очищает устаревший записи в кол-ве 20 штук (параметр ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP имеет значение 20). То есть за раз (каждый 100мс) Redis удаляет 200 записей. Если в системе кол-во устаревших записей превышает 25%, то редис, блокирует запись и пытается снизить этот показатель до 25%. Этот механизм призван защитить систему от нехватки памяти, которой требуется все больше для хранения истекших ключей*   

## Задача 3

Вы подняли базу данных MySQL для использования в гис-системе. При росте количества записей, в таблицах базы,
пользователи начали жаловаться на ошибки вида:
```python
InterfaceError: (InterfaceError) 2013: Lost connection to MySQL server during query u'SELECT..... '
```

Как вы думаете, почему это начало происходить и как локализовать проблему?

Какие пути решения данной проблемы вы можете предложить?

*Ошибка возникает из-за того, что в запросе клиент select-ит большой объем данных, то есть в терминах MYSQL передается слишком большой пакет с данными (communication packet). На сервере в конфигурации есть параметр allowed_max_packet, который необходимо увеличить до нужных значений (по умолчанию кажется размер пакета выставляется в 16 мегабайт - 16M). Обычно увеличение требуется когда клиент работает с так называемыми BLOB данными (Binary Large Object). Link for details https://dev.mysql.com/doc/refman/8.0/en/packet-too-large.html*

## Задача 4


Вы решили перевести гис-систему из задачи 3 на PostgreSQL, так как прочитали в документации, что эта СУБД работает с 
большим объемом данных лучше, чем MySQL.

После запуска пользователи начали жаловаться, что СУБД время от времени становится недоступной. В dmesg вы видите, что:

`postmaster invoked oom-killer`

Как вы думаете, что происходит?

Как бы вы решили данную проблему?

*Причина в недостатке ресурсов оперативной памяти: ядро ОС вызывает процесс oom-killer, чтобы завершить low priority процессы, чтобы не крашнуться самой. Некий инстинкт самосохранения как я понимаю. Что-то, а возможно сам Postgres потребляет слишком много опреативной памяти.   
Стоит посмотреть в сторону настроек параметров использования памяти в PG. Например,
shared_buffers - ПГ не работает напрямую с диском, а работает с данным буфером, кешем ОС. Процесс ПГ ищет нужные блоки сначала в буфере, а затем в кеше ОС, а затем уже на диске (что будет долго). Сама ОС также кеширует данные в оперативке, поэтому всю память отдавать под буфер нельзя. Рекомендуется 1/4 от всей RAM.   
work_mem - максимальное кол-во оперативки выделяемое на один запрос. Эта память выделяется отдельно на каждую операцию. Начинать стоит с 2-4% от доступной памяти. Думаю данный параметр стоит скоррелировать с max_connections  
max_connections - максимальное кол-во клиентов, которые могут подключиться к PostgreSQL. Для каждого клиента требуется свой work_mem*
